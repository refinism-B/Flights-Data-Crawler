{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf6ce55-05cc-49ab-85ec-08e8b0c74ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime, timedelta\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import FlightMod.CrawlList as fcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c495dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 函式庫\n",
    "\n",
    "# def safe_extract(func):\n",
    "#     \"\"\"判斷一個soup物件是否存在/有值，若沒有則回傳None\"\"\"\n",
    "#     try:\n",
    "#         return func()\n",
    "#     except (IndexError, AttributeError):\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def split_airport_code(code):\n",
    "#     if code is not None:\n",
    "#         code = code.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "#         if \"/\" in code:\n",
    "#             code1, code2 = code.split(\"/\")\n",
    "#             code1 = code1.strip()\n",
    "#             code2 = code2.strip()\n",
    "#         else:\n",
    "#             code1 = code\n",
    "#             code2 = code\n",
    "#     else:\n",
    "#         code1 = None\n",
    "#         code2 = None\n",
    "    \n",
    "#     return code1, code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9db0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判斷總列表.csv檔是否存在，若不存在則先建立一個只有columns的空表格\n",
    "file = 'C:/Users/add41/Documents/Data_Engineer/docker/Develop/FlightCrawler/FlightData/EVA_FlightList.csv'\n",
    "list_path = Path(file)\n",
    "\n",
    "if list_path.exists():\n",
    "    pass\n",
    "else:\n",
    "    columns = [\n",
    "        'query_date',\n",
    "        'flight_no',\n",
    "        'flight_type',\n",
    "        'departure_airport',\n",
    "        'departure_airport_code_1',\n",
    "        'departure_airport_code_2',\n",
    "        'arrival_airport',\n",
    "        'arrival_airport_code_1',\n",
    "        'arrival_airport_code_2',\n",
    "        'link',\n",
    "        'sync'\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e05c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入總表檔案\n",
    "df_list = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260dbded-38a4-4dd0-a857-d3b8fde0c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始查詢0到20筆資料...\n",
      "查詢EVA105班機資料...\n",
      "完成EVA105班機資料存取\n",
      "查詢EVA107班機資料...\n",
      "完成EVA107班機資料存取\n",
      "查詢EVA109班機資料...\n",
      "完成EVA109班機資料存取\n",
      "查詢EVA116班機資料...\n",
      "完成EVA116班機資料存取\n",
      "查詢EVA118班機資料...\n",
      "完成EVA118班機資料存取\n",
      "查詢EVA157班機資料...\n",
      "完成EVA157班機資料存取\n",
      "查詢EVA165班機資料...\n",
      "完成EVA165班機資料存取\n",
      "查詢EVA169班機資料...\n",
      "完成EVA169班機資料存取\n",
      "查詢EVA177班機資料...\n",
      "完成EVA177班機資料存取\n",
      "查詢EVA181班機資料...\n",
      "完成EVA181班機資料存取\n",
      "查詢EVA189班機資料...\n",
      "完成EVA189班機資料存取\n",
      "查詢EVA191班機資料...\n",
      "完成EVA191班機資料存取\n",
      "查詢EVA201班機資料...\n",
      "完成EVA201班機資料存取\n",
      "查詢EVA215班機資料...\n",
      "完成EVA215班機資料存取\n",
      "查詢EVA227班機資料...\n",
      "完成EVA227班機資料存取\n",
      "查詢EVA234班機資料...\n",
      "完成EVA234班機資料存取\n",
      "查詢EVA237班機資料...\n",
      "完成EVA237班機資料存取\n",
      "查詢EVA255班機資料...\n",
      "完成EVA255班機資料存取\n",
      "查詢EVA282班機資料...\n",
      "完成EVA282班機資料存取\n",
      "查詢EVA315班機資料...\n",
      "完成EVA315班機資料存取\n",
      "完成存取0到20筆資料\n",
      "開始查詢20到40筆資料...\n",
      "查詢EVA391班機資料...\n",
      "完成EVA391班機資料存取\n",
      "查詢EVA49班機資料...\n",
      "完成EVA49班機資料存取\n",
      "查詢EVA5班機資料...\n",
      "完成EVA5班機資料存取\n",
      "查詢EVA501班機資料...\n",
      "完成EVA501班機資料存取\n",
      "查詢EVA6班機資料...\n",
      "完成EVA6班機資料存取\n",
      "查詢EVA62班機資料...\n",
      "完成EVA62班機資料存取\n",
      "查詢EVA630班機資料...\n",
      "完成EVA630班機資料存取\n",
      "查詢EVA633班機資料...\n",
      "完成EVA633班機資料存取\n",
      "查詢EVA646班機資料...\n",
      "完成EVA646班機資料存取\n",
      "查詢EVA65班機資料...\n",
      "完成EVA65班機資料存取\n",
      "查詢EVA651班機資料...\n",
      "完成EVA651班機資料存取\n",
      "查詢EVA668班機資料...\n",
      "完成EVA668班機資料存取\n",
      "查詢EVA68班機資料...\n",
      "完成EVA68班機資料存取\n",
      "查詢EVA683班機資料...\n",
      "完成EVA683班機資料存取\n",
      "查詢EVA692班機資料...\n",
      "完成EVA692班機資料存取\n",
      "查詢EVA7班機資料...\n",
      "完成EVA7班機資料存取\n",
      "查詢EVA71班機資料...\n",
      "完成EVA71班機資料存取\n",
      "查詢EVA8班機資料...\n",
      "完成EVA8班機資料存取\n",
      "查詢EVA830班機資料...\n",
      "完成EVA830班機資料存取\n",
      "查詢EVA846班機資料...\n",
      "完成EVA846班機資料存取\n",
      "完成存取20到40筆資料\n",
      "開始查詢40到60筆資料...\n",
      "查詢EVA852班機資料...\n",
      "完成EVA852班機資料存取\n",
      "查詢EVA87班機資料...\n",
      "完成EVA87班機資料存取\n",
      "完成存取40到60筆資料\n",
      "開始查詢60到80筆資料...\n",
      "沒有60到80筆資料\n",
      "已完成存取資料\n"
     ]
    }
   ],
   "source": [
    "# 建立空list（為建立dataframe預備）並設定起始頁數，建立ss連線\n",
    "data = []\n",
    "logtime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "start_page = 0\n",
    "ss = requests.Session()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # 網頁為20筆一頁，設定從第0筆開始查詢，每次回圈+20，直到查無資料後break\n",
    "    # 利用ss.get發出請求並轉換出soup物件\n",
    "    url = f'https://www.flightaware.com/live/fleet/EVA?;offset={start_page};order=ident;sort=ASC'\n",
    "    headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36'}\n",
    "    res = ss.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    print(f'開始查詢{start_page}到{start_page + 20}筆資料...')\n",
    "\n",
    "\n",
    "    # 先判斷是否有資料，若找到「查無資料」的標籤，則設 found = True 終止迴圈\n",
    "    found = False\n",
    "    for tag in soup.find_all('i'):\n",
    "        if tag.text == \"Sorry. No matching flights found; try again later.\":\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "\n",
    "    # 若仍有資料 found = False 則繼續迴圈，分別尋找兩個標籤（兩種皆有連結）並合併list\n",
    "    if found == False:\n",
    "        table_list = soup('table', class_='prettyTable fullWidth')[0]('tr')[2:]\n",
    "\n",
    "        for i in table_list:\n",
    "            single = []\n",
    "            flight_no = i('td')[0].span.a.text\n",
    "            print(f'查詢{flight_no}班機資料...')\n",
    "\n",
    "            # 紀錄日期\n",
    "            single.append(logtime)\n",
    "\n",
    "            # 班機編號\n",
    "            single.append(fcl.safe_extract(lambda: i('td')[0].span.a.text))\n",
    "\n",
    "            # 機型\n",
    "            single.append(fcl.safe_extract(lambda: i('td')[1].span.a.text))\n",
    "\n",
    "            # 起飛機場\n",
    "            single.append(fcl.safe_extract(lambda: i('td')[2]('span', dir='ltr')[0].text))\n",
    "\n",
    "            # 起飛機場代號（如有兩種則分開儲存，只有一種則重複儲存）\n",
    "            code_d = fcl.safe_extract(lambda: i('td')[2]('span', dir='ltr')[1].text)\n",
    "            code_d1, code_d2 = fcl.split_airport_code(code_d)\n",
    "            single.append(code_d1)\n",
    "            single.append(code_d2)\n",
    "\n",
    "\n",
    "            # 降落機場\n",
    "            single.append(fcl.safe_extract(lambda: i('td')[3]('span', dir='ltr')[0].text))\n",
    "\n",
    "            # 降落機場代號（如有兩種則分開儲存，只有一種則重複儲存）\n",
    "            code_a = fcl.safe_extract(lambda: i('td')[3]('span', dir='ltr')[1].text)\n",
    "            code_a1, code_a2 = fcl.split_airport_code(code_a)\n",
    "            single.append(code_a1)\n",
    "            single.append(code_a2)\n",
    "\n",
    "            # 連結\n",
    "            single.append('https://www.flightaware.com' + fcl.safe_extract(lambda: i('td')[0].span.a['href']))\n",
    "\n",
    "            # 同步標記\n",
    "            single.append(0)\n",
    "\n",
    "            data.append(single)\n",
    "            print(f'完成{flight_no}班機資料存取')\n",
    "\n",
    "\n",
    "        # 完成後查詢筆數+20並稍微等待後在進行下一次迴圈\n",
    "        print(f'完成存取{start_page}到{start_page + 20}筆資料')\n",
    "        start_page += 20\n",
    "        time.sleep(15)\n",
    "\n",
    "\n",
    "    # 當查無資料時 found = True 顯示查無資料並終止迴圈\n",
    "    else:\n",
    "        print(f'沒有{start_page}到{start_page + 20}筆資料')\n",
    "        break\n",
    "\n",
    "print(f'已完成存取資料')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db2bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新資料建檔完成\n"
     ]
    }
   ],
   "source": [
    "# 根據爬蟲資料建立Dataframe\n",
    "columns = [\n",
    "    'query_date',\n",
    "    'flight_no',\n",
    "    'flight_type',\n",
    "    'departure_airport',\n",
    "    'departure_airport_code_1',\n",
    "    'departure_airport_code_2',\n",
    "    'arrival_airport',\n",
    "    'arrival_airport_code_1',\n",
    "    'arrival_airport_code_2',\n",
    "    'link',\n",
    "    'sync'\n",
    "]\n",
    "\n",
    "df2 = pd.DataFrame(columns=columns, data=data)\n",
    "print('新資料建檔完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2dfb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將機場名稱中的Int'l字樣去除，並去除前後空白\n",
    "df2['departure_airport'] = df2['departure_airport'].str.replace(\"Int\\'l\", \"\").str.replace(\"Intl\", \"\").str.strip()\n",
    "df2['arrival_airport'] = df2['arrival_airport'].str.replace(\"Int\\'l\", \"\").str.replace(\"Intl\", \"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f923519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成資料更新\n"
     ]
    }
   ],
   "source": [
    "# 直接將新資料與舊資料合併\n",
    "df_combine = pd.concat([df_list, df2], ignore_index=True)\n",
    "\n",
    "# 對合併後的資料使用drop_duplicates，將重複值刪去，並覆蓋回df_list\n",
    "df_list = df_combine.drop_duplicates(subset='link', keep = 'first').reset_index(drop=True)\n",
    "\n",
    "# 將query_date欄位轉換為datetime物件\n",
    "df_list['query_date'] = pd.to_datetime(df_list['query_date'])\n",
    "\n",
    "# 將新的df_list進行存檔\n",
    "df_list.to_csv(file, index=False)\n",
    "\n",
    "print('完成資料更新')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13d97fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6502f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
