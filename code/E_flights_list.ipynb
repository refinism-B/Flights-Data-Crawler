{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf90c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from Mods import pandas_mod as pdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69283418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col():\n",
    "    \"\"\"取得欄位名\"\"\"\n",
    "    return [\n",
    "        'query_date',\n",
    "        'flight_no',\n",
    "        'flight_type',\n",
    "        'departure_airport',\n",
    "        'departure_airport_code_1',\n",
    "        'departure_airport_code_2',\n",
    "        'arrival_airport',\n",
    "        'arrival_airport_code_1',\n",
    "        'arrival_airport_code_2',\n",
    "        'link',\n",
    "        # 'sync'\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_soup(corp, start_page, ss):\n",
    "    \"\"\"訪問FlightAware網頁取得soup物件\"\"\"\n",
    "    url = f'https://www.flightaware.com/live/fleet/{corp}?;offset={start_page};order=ident;sort=ASC'\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36'}\n",
    "    res = ss.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def page_exist_or_not(soup):\n",
    "    \"\"\"判斷這一頁是否有資料\"\"\"\n",
    "    page_exist = True\n",
    "    for tag in soup.find_all('i'):\n",
    "        if tag.text == \"Sorry. No matching flights found; try again later.\":\n",
    "            page_exist = False\n",
    "\n",
    "    return page_exist\n",
    "\n",
    "\n",
    "def split_airport_code(code):\n",
    "    \"\"\"若機場代碼有兩種形式，會將兩者分開，回傳兩個代碼\"\"\"\n",
    "    if code is not None:\n",
    "        code = code.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        if \"/\" in code:\n",
    "            code1, code2 = code.split(\"/\")\n",
    "            code1 = code1.strip()\n",
    "            code2 = code2.strip()\n",
    "        else:\n",
    "            code1 = code\n",
    "            code2 = code\n",
    "    else:\n",
    "        code1 = None\n",
    "        code2 = None\n",
    "\n",
    "    return code1, code2\n",
    "\n",
    "\n",
    "def safe_extract(func):\n",
    "    \"\"\"判斷一個soup物件是否存在/有值，若沒有則回傳None\"\"\"\n",
    "    try:\n",
    "        return func()\n",
    "    except (IndexError, AttributeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_flight_info(table_list, logtime):\n",
    "    page_data = []\n",
    "    for i in table_list:\n",
    "        single = []\n",
    "        flight_no = i('td')[0].span.a.text\n",
    "        print(f'查詢{flight_no}班機資料...')\n",
    "\n",
    "        # 紀錄日期\n",
    "        single.append(logtime)\n",
    "\n",
    "        # 班機編號\n",
    "        single.append(safe_extract(lambda: i('td')[0].span.a.text))\n",
    "\n",
    "        # 機型\n",
    "        single.append(safe_extract(lambda: i('td')[1].span.a.text))\n",
    "\n",
    "        # 起飛機場\n",
    "        single.append(safe_extract(lambda: i('td')[\n",
    "                      2]('span', dir='ltr')[0].text))\n",
    "\n",
    "        # 起飛機場代號（如有兩種則分開儲存，只有一種則重複儲存）\n",
    "        code_d = safe_extract(lambda: i('td')[2]('span', dir='ltr')[1].text)\n",
    "        code_d1, code_d2 = split_airport_code(code_d)\n",
    "        single.append(code_d1)\n",
    "        single.append(code_d2)\n",
    "\n",
    "        # 降落機場\n",
    "        single.append(safe_extract(lambda: i('td')[\n",
    "                      3]('span', dir='ltr')[0].text))\n",
    "\n",
    "        # 降落機場代號（如有兩種則分開儲存，只有一種則重複儲存）\n",
    "        code_a = safe_extract(lambda: i('td')[3]('span', dir='ltr')[1].text)\n",
    "        code_a1, code_a2 = split_airport_code(code_a)\n",
    "        single.append(code_a1)\n",
    "        single.append(code_a2)\n",
    "\n",
    "        # 連結\n",
    "        single.append('https://www.flightaware.com' +\n",
    "                      safe_extract(lambda: i('td')[0].span.a['href']))\n",
    "\n",
    "        # # 同步標記\n",
    "        # single.append(0)\n",
    "\n",
    "        # 存回page_data list\n",
    "        page_data.append(single)\n",
    "\n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35935269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始查詢EVA的第0到20筆資料...\n",
      "查詢EVA11班機資料...\n",
      "查詢EVA119班機資料...\n",
      "查詢EVA12班機資料...\n",
      "查詢EVA129班機資料...\n",
      "查詢EVA15班機資料...\n",
      "查詢EVA159班機資料...\n",
      "查詢EVA17班機資料...\n",
      "查詢EVA171班機資料...\n",
      "查詢EVA18班機資料...\n",
      "查詢EVA185班機資料...\n",
      "查詢EVA195班機資料...\n",
      "查詢EVA206班機資料...\n",
      "查詢EVA228班機資料...\n",
      "查詢EVA238班機資料...\n",
      "查詢EVA25班機資料...\n",
      "查詢EVA256班機資料...\n",
      "查詢EVA27班機資料...\n",
      "查詢EVA278班機資料...\n",
      "查詢EVA31班機資料...\n",
      "查詢EVA32班機資料...\n",
      "完成存取EVA的第0到20筆資料\n",
      "開始查詢EVA的第20到40筆資料...\n",
      "查詢EVA35班機資料...\n",
      "查詢EVA36班機資料...\n",
      "查詢EVA381班機資料...\n",
      "查詢EVA386班機資料...\n",
      "查詢EVA49班機資料...\n",
      "查詢EVA51班機資料...\n",
      "查詢EVA55班機資料...\n",
      "查詢EVA56班機資料...\n",
      "查詢EVA6班機資料...\n",
      "查詢EVA6003班機資料...\n",
      "查詢EVA6062班機資料...\n",
      "查詢EVA619班機資料...\n",
      "查詢EVA637班機資料...\n",
      "查詢EVA642班機資料...\n",
      "查詢EVA651班機資料...\n",
      "查詢EVA658班機資料...\n",
      "查詢EVA66班機資料...\n",
      "查詢EVA668班機資料...\n",
      "查詢EVA67班機資料...\n",
      "查詢EVA68班機資料...\n",
      "完成存取EVA的第20到40筆資料\n",
      "開始查詢EVA的第40到60筆資料...\n",
      "查詢EVA693班機資料...\n",
      "查詢EVA72班機資料...\n",
      "查詢EVA766班機資料...\n",
      "查詢EVA771班機資料...\n",
      "查詢EVA8班機資料...\n",
      "查詢EVA809班機資料...\n",
      "查詢EVA850班機資料...\n",
      "查詢EVA88班機資料...\n",
      "查詢EVA8836班機資料...\n",
      "查詢EVA9班機資料...\n",
      "完成存取EVA的第40到60筆資料\n",
      "開始查詢EVA的第60到80筆資料...\n",
      "EVA沒有第60到80筆資料\n",
      "已完成EVA存取資料\n",
      "EVA新資料建檔完成\n",
      "完成EVA資料更新，目前資料筆數：137\n",
      "5秒後繼續...\n",
      "開始查詢CAL的第0到20筆資料...\n",
      "查詢CAL105班機資料...\n",
      "查詢CAL109班機資料...\n",
      "查詢CAL11班機資料...\n",
      "查詢CAL117班機資料...\n",
      "查詢CAL123班機資料...\n",
      "查詢CAL127班機資料...\n",
      "查詢CAL163班機資料...\n",
      "查詢CAL173班機資料...\n",
      "查詢CAL177班機資料...\n",
      "查詢CAL187班機資料...\n",
      "查詢CAL21班機資料...\n",
      "查詢CAL222班機資料...\n",
      "查詢CAL23班機資料...\n",
      "查詢CAL3班機資料...\n",
      "查詢CAL31班機資料...\n",
      "查詢CAL5班機資料...\n",
      "查詢CAL504班機資料...\n",
      "查詢CAL5115班機資料...\n",
      "查詢CAL5122班機資料...\n",
      "查詢CAL5137班機資料...\n",
      "完成存取CAL的第0到20筆資料\n",
      "開始查詢CAL的第20到40筆資料...\n",
      "查詢CAL5141班機資料...\n",
      "查詢CAL5148班機資料...\n",
      "查詢CAL5154班機資料...\n",
      "查詢CAL52班機資料...\n",
      "查詢CAL5233班機資料...\n",
      "查詢CAL5236班機資料...\n",
      "查詢CAL5239班機資料...\n",
      "查詢CAL5255班機資料...\n",
      "查詢CAL5266班機資料...\n",
      "查詢CAL5267班機資料...\n",
      "查詢CAL528班機資料...\n",
      "查詢CAL5305班機資料...\n",
      "查詢CAL5311班機資料...\n",
      "查詢CAL5381班機資料...\n",
      "查詢CAL5637班機資料...\n",
      "查詢CAL62班機資料...\n",
      "查詢CAL64班機資料...\n",
      "查詢CAL6596班機資料...\n",
      "查詢CAL7班機資料...\n",
      "查詢CAL74班機資料...\n",
      "完成存取CAL的第20到40筆資料\n",
      "開始查詢CAL的第40到60筆資料...\n",
      "查詢CAL76班機資料...\n",
      "查詢CAL762班機資料...\n",
      "查詢CAL772班機資料...\n",
      "查詢CAL784班機資料...\n",
      "查詢CAL790班機資料...\n",
      "查詢CAL794班機資料...\n",
      "查詢CAL81班機資料...\n",
      "查詢CAL836班機資料...\n",
      "查詢CAL840班機資料...\n",
      "查詢CAL854班機資料...\n",
      "完成存取CAL的第40到60筆資料\n",
      "開始查詢CAL的第60到80筆資料...\n",
      "CAL沒有第60到80筆資料\n",
      "已完成CAL存取資料\n",
      "CAL新資料建檔完成\n",
      "完成CAL資料更新，目前資料筆數：148\n",
      "5秒後繼續...\n",
      "開始查詢SJX的第0到20筆資料...\n",
      "查詢SJX1班機資料...\n",
      "查詢SJX11班機資料...\n",
      "查詢SJX236班機資料...\n",
      "查詢SJX31班機資料...\n",
      "查詢SJX313班機資料...\n",
      "查詢SJX332班機資料...\n",
      "查詢SJX5班機資料...\n",
      "查詢SJX704班機資料...\n",
      "查詢SJX714班機資料...\n",
      "查詢SJX726班機資料...\n",
      "查詢SJX746班機資料...\n",
      "查詢SJX805班機資料...\n",
      "查詢SJX839班機資料...\n",
      "查詢SJX841班機資料...\n",
      "查詢SJX861班機資料...\n",
      "查詢SJX863班機資料...\n",
      "完成存取SJX的第0到20筆資料\n",
      "開始查詢SJX的第20到40筆資料...\n",
      "SJX沒有第20到40筆資料\n",
      "已完成SJX存取資料\n",
      "SJX新資料建檔完成\n",
      "完成SJX資料更新，目前資料筆數：50\n",
      "5秒後繼續...\n",
      "開始查詢TTW的第0到20筆資料...\n",
      "查詢TTW203班機資料...\n",
      "查詢TTW213班機資料...\n",
      "查詢TTW229班機資料...\n",
      "查詢TTW269班機資料...\n",
      "查詢TTW607班機資料...\n",
      "查詢TTW663班機資料...\n",
      "查詢TTW671班機資料...\n",
      "查詢TTW773班機資料...\n",
      "查詢TTW778班機資料...\n",
      "完成存取TTW的第0到20筆資料\n",
      "開始查詢TTW的第20到40筆資料...\n",
      "TTW沒有第20到40筆資料\n",
      "已完成TTW存取資料\n",
      "TTW新資料建檔完成\n",
      "完成TTW資料更新，目前資料筆數：36\n",
      "5秒後繼續...\n",
      "已完成所有航空公司資料更新！\n"
     ]
    }
   ],
   "source": [
    "flight_corp = [\"EVA\", \"CAL\", \"SJX\", \"TTW\"]\n",
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "for corp in flight_corp:\n",
    "    # 判斷總列表.csv檔是否存在，若不存在則先建立一個只有columns的空表格\n",
    "    folder = r\"C:\\Users\\add41\\Documents\\Data_Engineer\\Project\\Flights-Data-Crawler\\Data\"\n",
    "    file = f\"{today}_{corp}_FlightList.csv\"\n",
    "    columns = get_col()\n",
    "\n",
    "    df_main, file_path = pdm.read_or_build(folder, file, columns)\n",
    "\n",
    "    # 建立空list（為建立dataframe預備）並設定起始頁數，建立ss連線\n",
    "    data = []\n",
    "    logtime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    start_page = 0\n",
    "    ss = requests.Session()\n",
    "\n",
    "    while True:\n",
    "        # 網頁為20筆一頁，設定從第0筆開始查詢，每次回圈+20，直到查無資料後break\n",
    "        # 利用ss.get發出請求並轉換出soup物件\n",
    "        soup = get_soup(corp, start_page, ss)\n",
    "        print(f'開始查詢{corp}的第{start_page}到{start_page + 20}筆資料...')\n",
    "\n",
    "        # 若仍有資料 found = False 則繼續迴圈，分別尋找兩個標籤（兩種皆有連結）並合併list\n",
    "        if page_exist_or_not(soup):\n",
    "            table_list = soup('table', class_='prettyTable fullWidth')[\n",
    "                0]('tr')[2:]\n",
    "            page_data = get_flight_info(table_list, logtime)\n",
    "\n",
    "            for single_data in page_data:\n",
    "                data.append(single_data)\n",
    "\n",
    "            # 完成後查詢筆數+20並稍微等待後在進行下一次迴圈\n",
    "            print(f'完成存取{corp}的第{start_page}到{start_page + 20}筆資料')\n",
    "            start_page += 20\n",
    "            time.sleep(10)\n",
    "\n",
    "        # 當查無資料時 found = True 顯示查無資料並終止迴圈\n",
    "        else:\n",
    "            print(f'{corp}沒有第{start_page}到{start_page + 20}筆資料')\n",
    "            break\n",
    "\n",
    "    print(f'已完成{corp}存取資料')\n",
    "\n",
    "    # 根據爬蟲資料建立Dataframe\n",
    "    columns = get_col()\n",
    "\n",
    "    df_corp = pd.DataFrame(columns=columns, data=data)\n",
    "    print(f'{corp}新資料建檔完成')\n",
    "\n",
    "    # 直接將新資料與舊資料合併\n",
    "    df_main = pd.concat([df_main, df_corp], ignore_index=True)\n",
    "\n",
    "    # 對合併後的資料使用drop_duplicates，將重複值刪去，並覆蓋回df_main\n",
    "    df_main = df_main.drop_duplicates(\n",
    "        subset='link', keep='first').reset_index(drop=True)\n",
    "\n",
    "    # 將query_date欄位轉換為datetime物件\n",
    "    df_main['query_date'] = pd.to_datetime(df_main['query_date'])\n",
    "\n",
    "    # 將新的df_main進行存檔\n",
    "    df_main.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f'完成{corp}資料更新，目前資料筆數：{len(df_main)}')\n",
    "    print('5秒後繼續...')\n",
    "    time.sleep(5)\n",
    "\n",
    "print('已完成所有航空公司資料更新！')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flights-data-crawler-HkKwTBFH-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
